import csv
import sys
import os
import json
import string
from typing import List
from collections import defaultdict

useSaving = True
useHIpc = False


class Instruction:
    def __init__(self, seq, pc, asm, lastCmt, dispatch, ReadOp, Execute, writeBack, commit, is_branch):
        self.seq = int(seq)
        self.pc = pc
        self.asm = asm
        self.start = int(lastCmt)
        self.latency = int(commit) - int(lastCmt)
        self.dispatch = int(dispatch)
        self.ReadOp = int(ReadOp)
        self.Execute = int(Execute)
        self.writeBack = int(writeBack)
        self.commit = int(commit)
        self.is_branch = bool(int(is_branch))
        self._ipc = None  # å»¶è¿Ÿåˆ†é…çš„ IPCï¼ˆå¯èƒ½æ˜¯ N/latencyï¼‰

    @property
    def ipc(self):
        return self._ipc if self._ipc is not None else (1 / self.latency if self.latency > 0 else 0)

class BasicBlock:
    def __init__(self, block_id):
        self.block_id = block_id
        self.iterations = []  # æ¯æ¬¡è¿­ä»£æ˜¯ä¸€ç»„æŒ‡ä»¤

    def add_iteration(self, instrs):
        self.iterations.append(instrs)

    def total_cycles(self):
        if not self.iterations:
            return 0
        total = 0
        for it in self.iterations:
            if not it:
                continue
            min_start = min(instr.start for instr in it)
            max_end   = max(instr.start + instr.latency for instr in it)
            total += (max_end - min_start)
        return total

    def avg_ipc(self):
        total_instrs = sum(len(it) for it in self.iterations)
        total_cycles = self.total_cycles()
        return total_instrs / total_cycles if total_cycles else 0

    def iteration_info(self):
        infos = []
        avg_ipc = self.avg_ipc()
        for idx, it in enumerate(self.iterations):
            if not it:
                continue
            min_start = min(instr.start for instr in it)
            max_end   = max(instr.start + instr.latency for instr in it)
            cycles = max_end - min_start
            ipc = len(it) / cycles if cycles else 0
            infos.append({
                "iter_id": idx + 1,  # åŸå§‹è¿­ä»£å·
                "cycles": cycles,
                "ipc": ipc,
                "instrs": it,   # ç›´æ¥å­˜ Instruction å¯¹è±¡
                "below_avg": ipc < 2 #avg_ipc +0.5
            })
        return infos

def classify_instruction(asm: str) -> str:
    """æ ¹æ®æŒ‡ä»¤åŠ©è®°ç¬¦åˆ†ç±»"""
    asm_lower = asm.lower()
    if asm_lower.startswith(("lb", "lh", "lw", "lbu", "lhu")):
        return "Load"
    elif asm_lower.startswith(("sb", "sh", "sw")):
        return "Store"
    elif asm_lower.startswith(("beq", "bne", "blt", "bge", "bltu", "bgeu", "jal", "jalr")):
        return "Branch"
    elif asm_lower.startswith(("cal_stream")):
        return "CAL-STREAM"
    elif asm_lower.startswith(("step_i","cfg_")):
        return "MISC-STREAM"
    elif asm_lower.startswith(("mul")):
        return "multiply"
    else:
        return "Compute"

def output_instrview_json(instrs: List[Instruction], output_path="instrview.json"):
    """è¾“å‡ºæ¯æ¡æŒ‡ä»¤çš„æ—¶é—´æ®µä¸ç±»å‹ä¿¡æ¯"""
    instr_events = []
    for instr in instrs:
        # åŸºæœ¬å­—æ®µ
        event = {
            "name": instr.asm,
            "cname": "a",
            "ph": "X",
            "pid": "cpu",
            "tid": classify_instruction(instr.asm),
            "ts": instr.start,
            "dur": instr.latency,
        }
        instr_events.append(event)

    with open(output_path, "w") as f:
        json.dump(instr_events, f, indent=2)
    print(f"[+] Instruction-level trace written to {output_path}")


def analyze_instructions_by_pc(instructions, output_file="pc_stats.txt"):
    """
    æ ¹æ® PC åˆ†ç±»ç»Ÿè®¡æŒ‡ä»¤æ€§èƒ½ï¼Œè¾“å‡ºä¸ºé€—å·åˆ†éš”æ ¼å¼ï¼ˆå« asm å’Œæ€» IPCï¼‰ã€‚
    """
    stats = defaultdict(lambda: {"total_cycles": 0.0, "count": 0, "asm": None})
    type_stats = defaultdict(lambda: {"total_cycles": 0.0, "count": 0})  # æ–°å¢
    total_cycles = 0.0

    # èšåˆæ¯æ¡æŒ‡ä»¤
    for inst in instructions:
        cycle = 1 / inst.ipc if inst.ipc > 0 else 0
        total_cycles += cycle

        # --- æŒ‰ PC ç»Ÿè®¡ ---
        if stats[inst.pc]["asm"] is None:
            stats[inst.pc]["asm"] = inst.asm
        stats[inst.pc]["total_cycles"] += cycle
        stats[inst.pc]["count"] += 1

        # --- æŒ‰ç±»å‹ç»Ÿè®¡ ---
        itype = classify_instruction(inst.asm)
        type_stats[itype]["total_cycles"] += cycle
        type_stats[itype]["count"] += 1

    # --- æŒ‰ total_cycles ä»å¤§åˆ°å°æ’åº ---
    sorted_stats = sorted(stats.items(), key=lambda kv: kv[1]["total_cycles"], reverse=True)

    # --- è¾“å‡ºæ–‡ä»¶ ---
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("pc,asm,count,total_cycles,avg_cycles\n")
        for pc, data in sorted_stats:
            asm_safe = data["asm"].replace('"', '""')
            avg_cycles = data["total_cycles"] / data["count"] if data["count"] > 0 else 0
            f.write(f'{pc},"{asm_safe}",{data["count"]},{data["total_cycles"]:.6f},{avg_cycles:.6f}\n')

        f.write(f"\nTOTAL_Cycles,{total_cycles:.6f}\n\n")

        # --- è¾“å‡ºåˆ†ç±»ç»Ÿè®¡ ---
        f.write("Type,count,total_cycles,avg_cycles,save_cycles\n")
        for t, d in type_stats.items():
            avg_cycles = d["total_cycles"] / d["count"] if d["count"] > 0 else 0
            save_cycles = d['total_cycles'] - d["count"] / 2
            f.write(f"{t},{d['count']},{d['total_cycles']:.6f},{avg_cycles:.6f},{save_cycles:.1f}\n")

    print(f"âœ… å·²è¾“å‡º {len(sorted_stats)} æ¡ PC ç»Ÿè®¡ç»“æœåˆ° {output_file}")
    print(f"ğŸ“Š æ‰€æœ‰æŒ‡ä»¤ total_cycles æ€»å’Œ = {total_cycles:.6f}")
    return sorted_stats, total_cycles, type_stats
def parse_trace_file(filename):
    instrs = []
    with open(filename, newline="") as f:
        reader = csv.reader(f)
        next(reader) 
        for seq, row in enumerate(reader):
            if not row:
                continue
            pc, asm, fetch, preDecode, decode, dispatch, issue, ReadOp, Execute,Execute1,Execute2, writeBack,writeBackROB, commit,lastCmt , is_branch = row[:16]
            instrs.append(Instruction(seq, pc, asm, lastCmt, dispatch, ReadOp, Execute, writeBack, commit, is_branch))

    # è°ƒæ•´ IPCï¼šåŒä¸€ start çš„ N æ¡æŒ‡ä»¤å…±äº« latency
    start_groups = defaultdict(list)
    for instr in instrs:
        start_groups[instr.start].append(instr)

    for group in start_groups.values():
        n = len(group)
        if n == 0:
            continue
        latency = group[0].latency
        per_instr_ipc = n / latency if latency > 0 else 0
        for instr in group:
            instr._ipc = per_instr_ipc

    return instrs

def analyze_pipeline_stages(instructions, output_file="pipeline_stage_stats.csv"):
    """
    ç»Ÿè®¡æ¯æ¡æŒ‡ä»¤ä» lastCmtCycle å¼€å§‹ï¼Œåˆ° commit ä¹‹é—´çš„æµæ°´çº§è€—æ—¶ï¼ˆæŒ‰ PC èšåˆï¼‰ã€‚
    è‹¥ç›¸é‚»ä¸¤æ¡æŒ‡ä»¤ commit ç›¸åŒï¼ˆåŒå‘¨æœŸé€€ä¼‘ï¼‰ï¼Œåˆ™è·³è¿‡åè€…ã€‚
    å¹¶æŒ‰æŒ‡ä»¤ç§ç±»ç»Ÿè®¡æ¯ä¸ªæµæ°´çº§è€—æ—¶ã€‚
    """
    from collections import defaultdict

    stats = defaultdict(lambda: {"count": 0, "total_cycles": 0.0, "asm": None})
    stage_totals = defaultdict(float)  # æ¯ä¸ªæµæ°´çº§æ€»å’Œ
    stage_type_totals = defaultdict(lambda: defaultdict(float))  # stage -> type -> cycles

    if not instructions:
        print("âš ï¸ analyze_pipeline_stages: empty instruction list")
        return

    instrs = sorted(instructions, key=lambda x: x.seq)

    prev_commit = instrs[0].commit
    for inst in instrs[1:]:
        if inst.commit == prev_commit:
            prev_commit = inst.commit
            continue

        lc = inst.start
        d, rf, ex, wb, cm = inst.dispatch, inst.ReadOp, inst.Execute, inst.writeBack, inst.commit
        stage_durations = {}

        # ç¡®å®š lastCmt æ‰€åœ¨é˜¶æ®µå¹¶è®¡ç®—å„é˜¶æ®µè€—æ—¶
        if lc < d:
            stage_durations["lastCmt->dispatch"] = d - lc
            stage_durations["dispatch->readop"] = rf - d
            stage_durations["readop->execute"] = ex - rf
            stage_durations["execute->writeback"] = wb - ex
            stage_durations["writeback->retire"] = cm - wb
        elif d <= lc < rf:
            stage_durations["dispatch->readop"] = rf - lc
            stage_durations["readop->execute"] = ex - rf
            stage_durations["execute->writeback"] = wb - ex
            stage_durations["writeback->retire"] = cm - wb
        elif rf <= lc < ex:
            stage_durations["readop->execute"] = ex - lc
            stage_durations["execute->writeback"] = wb - ex
            stage_durations["writeback->retire"] = cm - wb
        elif ex <= lc < wb:
            stage_durations["execute->writeback"] = wb - lc
            stage_durations["writeback->retire"] = cm - wb
        elif wb <= lc < cm:
            stage_durations["writeback->retire"] = cm - lc

        instr_type = classify_instruction(inst.asm)

        for stage, val in stage_durations.items():
            if val <= 0:
                continue
            # æŒ‰ PC èšåˆ
            key = (stage, inst.pc)
            entry = stats[key]
            if entry["asm"] is None:
                entry["asm"] = inst.asm
            entry["count"] += 1
            entry["total_cycles"] += val

            # æŒ‰æµæ°´çº§æ€»å’Œ
            stage_totals[stage] += val
            # æŒ‰æµæ°´çº§+æŒ‡ä»¤ç±»å‹æ€»å’Œ
            stage_type_totals[stage][instr_type] += val

        prev_commit = inst.commit

    # è¾“å‡º CSV
    rows = []
    for (stage, pc), data in stats.items():
        avg = data["total_cycles"] / data["count"] if data["count"] else 0
        rows.append((stage, pc, data["asm"], data["count"], data["total_cycles"], avg))

    rows.sort(key=lambda x: (x[0], -x[4]))

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("Stage,PC,ASM,Count,Total_Cycles,Avg_Cycles\n")
        for stage, pc, asm, cnt, total, avg in rows:
            asm_safe = asm.replace('"', '""') if asm else ""
            f.write(f'{stage},{pc},"{asm_safe}",{cnt},{total:.3f},{avg:.3f}\n')

        # è¾“å‡ºæ¯ä¸ªæµæ°´çº§æ€»å’Œ
        f.write("\n# Stage Totals\n")
        total_cycles_all = 0.0
        for stage, total in stage_totals.items():
            f.write(f'{stage}_TOTAL,{total:.3f}\n')
            total_cycles_all += total
        f.write(f'ALL_STAGES_TOTAL,{total_cycles_all:.3f}\n\n')

        # è¾“å‡ºæ¯ä¸ªæµæ°´çº§æŒ‰æŒ‡ä»¤ç±»å‹çš„æ€»å’Œ
        f.write("# Stage Totals by Instruction Type\n")
        for stage, type_dict in stage_type_totals.items():
            for instr_type, total in type_dict.items():
                f.write(f'{stage}_{instr_type}_TOTAL,{total:.3f}\n')

    print(f"âœ… è¾“å‡ºæ–‡ä»¶: {output_file} ï¼ˆå…± {len(rows)} æ¡ç»Ÿè®¡ï¼‰")
    print(f"ğŸ“Š å„æµæ°´çº§æ€»å’Œå·²é™„åŠ ï¼ŒALL_STAGES_TOTAL={total_cycles_all:.3f}")
  
def build_basic_blocks(instrs):
    """
    æ›´ç¨³å¥çš„ basic-block æ„é€ ï¼š
    1) å…ˆè¯†åˆ«æ‰€æœ‰ block èµ·ç‚¹ï¼ˆblock_startsï¼‰ï¼š
       - ç¬¬ 0 æ¡æŒ‡ä»¤ä¸€å®šæ˜¯ä¸€ä¸ªèµ·ç‚¹
       - å¦‚æœ instr[i].pc != instr[i-1].pc + 4ï¼ˆéé¡ºåºï¼‰ï¼Œåˆ™ instr[i] æ˜¯èµ·ç‚¹
       - å¦‚æœ instr[i-1] æ˜¯åˆ†æ”¯/è·³è½¬æŒ‡ä»¤ï¼ˆinstr[i-1].is_branchï¼‰ï¼Œåˆ™ instr[i] ä¹Ÿæ˜¯èµ·ç‚¹
    2) ç¬¬äºŒéæŒ‰èµ·ç‚¹åˆ‡åˆ†ï¼šé‡åˆ°èµ·ç‚¹å°±æŠŠä¸Šä¸€ä¸ªç§¯ç´¯çš„ current_block æ”¶å°¾å¹¶åŠ å…¥å¯¹åº”çš„ BasicBlockï¼ˆæŒ‰èµ·ç‚¹åœ°å€åš keyï¼‰
    3) ä¿è¯æ¯æ¬¡åˆ°è¾¾æŸä¸ªèµ·ç‚¹éƒ½ä¼šäº§ç”Ÿä¸€æ¬¡è¿­ä»£ï¼ˆå³ä¾¿åªæœ‰ 1 æ¡æŒ‡ä»¤ï¼‰
    è¿”å›å€¼ï¼šlist(BasicBlock)ï¼Œé¡ºåºæ˜¯æŒ‰é¦–æ¬¡å‡ºç°é¡ºåºåˆ†é… block_idã€‚
    """
    if not instrs:
        return []

    # è§„èŒƒåŒ– pc å­—ç¬¦ä¸² (å°å†™ hex)ï¼Œé¿å…å¤§å°å†™æˆ–æ ¼å¼é—®é¢˜
    def pc_norm(pc_str):
        return pc_str.lower()

    # 1) è¯†åˆ«æ‰€æœ‰ block èµ·ç‚¹
    block_starts = set()
    block_starts.add(pc_norm(instrs[0].pc))
    for i in range(1, len(instrs)):
        prev = instrs[i-1]
        cur = instrs[i]
        try:
            expected = f"0x{int(prev.pc, 16) + 4:x}"
        except Exception:
            expected = None
        if expected is None or pc_norm(cur.pc) != expected:
            # éé¡ºåºå–æŒ‡ -> æ–°èµ·ç‚¹ï¼ˆå¯èƒ½æ˜¯è·³è½¬ç›®æ ‡æˆ–å¼‚å¸¸/å‡½æ•°è¾¹ç•Œï¼‰
            block_starts.add(pc_norm(cur.pc))
        if prev.is_branch:
            # ä¸Šä¸€æ¡æ˜¯åˆ†æ”¯/è¿”å›/è·³è½¬ -> ä¸‹ä¸€æ¡ä¹Ÿæ˜¯èµ·ç‚¹ï¼ˆæ˜¾å¼ï¼‰
            block_starts.add(pc_norm(cur.pc))

    # 2) ç¬¬äºŒéæŒ‰èµ·ç‚¹åˆ‡åˆ†å¹¶æ”¶é›† iterations
    blocks_map = {}           # key: start_pc -> BasicBlock
    block_id_counter = 0
    current_start = None
    current_block = []

    for instr in instrs:
        p = pc_norm(instr.pc)
        if p in block_starts:
            # æ–°èµ·ç‚¹å‡ºç°ï¼šå…ˆæŠŠä¸Šä¸€ä¸ªç§¯ç´¯çš„ block å…³é—­å¹¶åŠ å…¥å¯¹åº” BasicBlock
            if current_block:
                # if instr.start == current_block[-1].start :
                #     print(instr.seq)
                if current_start not in blocks_map:
                    blocks_map[current_start] = BasicBlock(block_id_counter)
                    block_id_counter += 1
                blocks_map[current_start].add_iteration(current_block)
                if p != current_start:
                    print(blocks_map[current_start].block_id,"è¿­ä»£æ¬¡æ•°ï¼š",len(blocks_map[current_start].iterations))
            # å¯åŠ¨ä¸€ä¸ªæ–°çš„ current_blockï¼Œä»¥å½“å‰ pc ä½œä¸º key
            current_start = p
            current_block = [instr]
        else:
            # ç»§ç»­å½“å‰ block çš„è¿­ä»£
            current_block.append(instr)

    # å¤„ç†æœ«å°¾æ®‹ä½™
    if current_block:
        if current_start not in blocks_map:
            blocks_map[current_start] = BasicBlock(block_id_counter)
            block_id_counter += 1
        blocks_map[current_start].add_iteration(current_block)

    # æŒ‰é¦–æ¬¡å‡ºç°é¡ºåºè¿”å› blocksï¼ˆblocks_map çš„å€¼å·²ç»æŒ‰åˆ›å»ºé¡ºåºåˆ†é… block_idï¼‰
    # è¿”å› list æŒ‰ block_id æ’åºï¼Œä¿è¯è¾“å‡ºç¨³å®š
    blocks_list = sorted(blocks_map.values(), key=lambda b: b.block_id)
    return blocks_list
GROUP_SIZE = 5120
SUB_SIZE   = 512     # æ¯å±‚å›ºå®š 512 è¡Œ
SUB_COUNT  = GROUP_SIZE // SUB_SIZE   # = 10
def dump_grouped_infos(it_infos, outfile):
    total = len(it_infos)
    group_id = 0

    for g_start in range(0, total, GROUP_SIZE):
        g_end = min(g_start + GROUP_SIZE, total)
        group = it_infos[g_start: g_end]

        # ===== æ‰“å°å¤§æ ‡é¢˜ =====
        outfile.write("\n")
        outfile.write("=" * 60 + "\n")
        outfile.write(f"å¤§ç»„ {group_id}ï¼šè¿­ä»£ {group[0]['iter_id']} â€“ {group[-1]['iter_id']}\n")
        outfile.write("=" * 60 + "\n\n")

        group_total_cycles = 0   # <== å¤§ç»„æ€» cycles

        # ===== 5120 å†…éƒ¨åˆ† 10 ä¸ªå°å±‚ï¼Œæ¯å±‚ 512 è¡Œ =====
        for sub_id in range(SUB_COUNT):
            s_start = sub_id * SUB_SIZE
            s_end   = s_start + SUB_SIZE

            if s_start >= len(group):  # ä¸è¶³ 5120 æ—¶æå‰é€€å‡º
                break

            sub = group[s_start:s_end]

            outfile.write(f"  {group_id}.{sub_id+1} å±‚: è¿­ä»£ {sub[0]['iter_id']} â€“ {sub[-1]['iter_id']}\n")

            sub_total_cycles = 0  # <== å°å±‚æ€» cycles

            for info in sub:
                outfile.write(
                    f"    è¿­ä»£ {info['iter_id']}: è€—æ—¶={info['cycles']} cycles, IPC={info['ipc']:.2f}\n"
                )
                sub_total_cycles += info["cycles"]

            # è¾“å‡ºå°å±‚æ€»è€—æ—¶
            outfile.write(f"    â†’ æœ¬å±‚æ€»è€—æ—¶ï¼š{sub_total_cycles} cycles\n\n")

            group_total_cycles += sub_total_cycles

        # è¾“å‡ºå¤§ç»„æ€»è€—æ—¶
        outfile.write(f"  â†’ å¤§ç»„æ€»è€—æ—¶ï¼š{group_total_cycles} cycles\n")

        group_id += 1
def main():
    imgname = sys.argv[1] + "-riscv32"
    trace_file = os.path.join("profiling", imgname, "base.log")
    output_dir = os.path.join("profiling", imgname)
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, "blkinfo-sim")
    view_file = os.path.join(output_dir, "blkview.json")  # æ–°å¢ view æ–‡ä»¶
    instr_file =  os.path.join(output_dir, "instrview.csv")
    pipeline_file = os.path.join(output_dir, "pipeline_stage_stats.csv")

    instrs = parse_trace_file(trace_file)
    blocks = build_basic_blocks(instrs)

    total_cycles = 0
    if instrs:
        total_cycles = max(instr.start + instr.latency for instr in instrs) - min(instr.start for instr in instrs)
    overall_instrs = len(instrs)
    overall_ipc = overall_instrs / total_cycles if total_cycles else 0
    avg_cycles_per_block = total_cycles / len(blocks) if blocks else 0

    with open(output_file, "w") as outfile:
        outfile.write(f"ç¨‹åºçš„åŸºæœ¬å—æ•°é‡: {len(blocks)}\n")
        outfile.write(f"æ€»æ‰§è¡Œ cycles: {total_cycles}\n")
        outfile.write(f"æ€»æŒ‡ä»¤æ•°: {overall_instrs}\n")
        outfile.write(f"æ€»ä½“ IPC: {overall_ipc:.2f}\n\n")

        sorted_blocks = sorted(blocks, key=lambda bb: bb.total_cycles(), reverse=True)
        # --- ç²—ç•¥åŸºæœ¬å—ä¿¡æ¯ï¼ˆæŒ‰é¢„ä¼°ä¼˜åŒ–æ”¶ç›Šæ’åºï¼‰ ---
        if useSaving:
            #outfile.write("æŒ‰é¢„ä¼°ä¼˜åŒ–æ”¶ç›Šæ’åºçš„åŸºæœ¬å—ï¼ˆå æ¯”é«˜äºå¹³å‡ï¼‰:\n")
            avg_percent = 0 # 1 / 200 #len(blocks) if blocks else 0
            block_savings = []
            for bb in blocks:
                bb_instr_count = sum(len(it) for it in bb.iterations)
                bb_cycles = bb.total_cycles()
                # é¢„ä¼°ä¼˜åŒ– IPC = 2
                optimized_cycles = bb_instr_count / 2
                savings = bb_cycles - optimized_cycles
                savings_percent = savings / total_cycles if total_cycles else 0
                block_savings.append((bb, savings_percent, bb_cycles))
            # æŒ‰ savings_percent æ’åº
            cumulative_percent = 0.0
            cumulative_cycles = 0
            block_savings.sort(key=lambda x: x[2], reverse=True)
            #block_savings.sort(key=lambda x: x[0].block_id, reverse=False)
            for bb, savings_percent, bb_cycles in block_savings:
                if savings_percent < avg_percent:
                    continue
                block_percent = bb_cycles / total_cycles * 100
                cumulative_percent += block_percent
                cumulative_cycles += bb_cycles
                outfile.write(
                    f"Block {bb.block_id}: æ€»cycles={bb_cycles}, å æ¯”={(bb_cycles/total_cycles):.2f}, "
                    f"è¿­ä»£æ¬¡æ•° {len(bb.iterations)}, "
                    f"ç´¯è®¡cycles={cumulative_cycles}, "
                    f"å½“å‰IPC={bb.avg_ipc():.2f}\n"
                )
        
        if useHIpc:
            for bb in blocks:
                bb_cycles = bb.total_cycles()
                it_infos = bb.iteration_info()
                it_infos.sort(key=lambda x: x["cycles"])  
                lowest_cycles = it_infos[0]['cycles']
                optimize_cycles = lowest_cycles * len(bb.iterations)
                save_cycles = bb_cycles - optimize_cycles
                if save_cycles / bb_cycles < 0.1 or bb_cycles / total_cycles < 0.02:
                    continue
                outfile.write(f"åŸºæœ¬å— {bb.block_id}, æ€»è€—æ—¶: {bb_cycles} cycles, è¿­ä»£æ¬¡æ•°: {len(bb.iterations)}, å¹³å‡IPC: {bb.avg_ipc():.2f}, å¯ä¼˜åŒ–å‘¨æœŸ: {save_cycles},å æ¯”: {(save_cycles / bb_cycles):.2f}\n")

        outfile.write("\n")
        # --- è¯¦ç»†åŸºæœ¬å—ä¿¡æ¯ï¼ˆæŒ‰é¢„ä¼°ä¼˜åŒ–æ”¶ç›Šæ’åºï¼‰ ---
        for bb, savings_percent, bb_cycles in block_savings:
            if savings_percent < avg_percent:
                continue
            outfile.write(f"=== åŸºæœ¬å— {bb.block_id} ===\n")
            outfile.write(f"æ€»è€—æ—¶: {bb_cycles} cycles, å¹³å‡IPC: {bb.avg_ipc():.2f}\n")
            outfile.write(f"è¿­ä»£æ¬¡æ•°: {len(bb.iterations)}\n")

            # block å†…è¿­ä»£æŒ‰ IPC ä»ä½åˆ°é«˜æ’åº
            it_infos = bb.iteration_info()
            #it_infos.sort(key=lambda x: x["ipc"], reverse=True)  # æŒ‰ IPC æ’åºå±•ç¤ºï¼Œä½†ä¿ç•™ iter_id
            if bb.block_id == 20:
                dump_grouped_infos(it_infos, outfile)
            # cycles_dict = defaultdict(list)
            # for info in it_infos:
            #     cycles_dict[info["cycles"]].append(info["iter_id"])
            # for cycles in sorted(cycles_dict.keys()):
            #     iter_ids = " ".join(str(i) for i in sorted(cycles_dict[cycles]))
            #     outfile.write(f"    è¿­ä»£ {iter_ids}, è€—æ—¶={cycles} cycles\n")
            # for info in it_infos:
            #     if not info["below_avg"]:
            #         continue
            #     outfile.write(f" è¿­ä»£ {info['iter_id']}: è€—æ—¶={info['cycles']} cycles, IPC={info['ipc']:.2f}\n")

            #     prev_start = None
            #     for instr in info["instrs"]:
            #         pc_str = f"{instr.pc:<12}"
            #         asm_str = f"{instr.asm:<30}"
            #         start_str = f"start={instr.start:<5}"
            #         delay_str = f"delay={instr.latency:<3}"

            #         # å¦‚æœå½“å‰å‘¨æœŸä¸ä¸Šä¸€æ¡ä¸åŒï¼Œåˆ™æ ‡è®°ä¸ºç¬¬ä¸€æ¡æŒ‡ä»¤
            #         mark = "*" if instr.start != prev_start else ""
            #         prev_start = instr.start

            #         outfile.write(f"    {pc_str} {asm_str} {start_str} {delay_str} {mark}\n")

if __name__ == "__main__":
    main()
